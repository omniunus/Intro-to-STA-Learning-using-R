Resampling Methods:
Seperating the data set into traning and testing, repeatedly fitting different trainings to model and calculate the test MSE.
Cross Validation could have two purposes: evaluate the performance is called model assessment, help selecting the best level of flexibility is called mode selection.

  1. Validation Set approach
  2. Corss Validation (used for model assessment or model selection)
     2.1 Leave-One-Out Cross Validation (LOOCV)
     2.2 K-Fold Cross Validation
  3. Bootstrap

I. Validation
Processes:
  Randomly divide the data set into training and test, euqally n for each. build model from training, predict the response and calc test MSE.
  Repeat many times.
Drawbacks:
  test error rate highly variable, prediction model bad due to lacking data in the training set
  to fix the drawbacks, we have LOOCV

II. Leave-One-Out Cross-Validation (LOOCV)
  only have a single observation as the validation (test) set;
  Thus MSE bias significantly reduced, however hingly variable. Question: IF MANY REPEATINGS COULD REDUCE THE VARIABILITY ???
  Drawback is hardware limitation.

III. K-Fold Cross-Validation
  


